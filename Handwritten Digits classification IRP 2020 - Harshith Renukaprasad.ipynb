{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How increasing the amount of training data for a machine learning algorithm that recognizes handwritten digits increases the accuracy of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Harshith Renukaprasad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is the scientific study of algorithms ancd statistical models that computers use to perform a specific task without a human explicitly asking it to do so. Practically, this means giving the computer a training set of images for the computer to learn the difference between a 3 and an 8 for example, and then give the image an image of a 3 it has not seen before and predict what number it is based on what it has learnt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Goal of the project is to progressively increase the amount of training images available to the computer from  100 to 50,000 and document the increased accuracy and decreased loss of the algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Materials required for the project:\n",
    "\n",
    "Disclaimer: Most of the materials included are digital.\n",
    "\n",
    "Another Disclaimer: This project was done on Visual Studio Code, but is submitted/presented in Jupyter notebook for the users ease in readablity.\n",
    "\n",
    "1. The first and foremost thing required for this project is a computer with  [Visual Studio Code ](https://code.visualstudio.com/download) (200  megabytes, Windows 64 bit) installed. Note that the computer needs to  have atleast 1 gigabyte of ram and 5 gigabytes of storage available. The computer, very importantly, also requires a stable internet connection. Finally, [Python 3.7.6](https://www.python.org/ftp/python/3.7.6/python-3.7.6-amd64.exe) (downloaded, and added to path throught the installer)needs to be installed on the system\n",
    "\n",
    "\n",
    "2. A google account to login to the websites [Hackerrank](https://www.hackerrank.com/), and [Youtube](https://www.youtube.com/channel/UCCezIgC97PvUuR4_gbFUs5g). Hackerrank is a very popular website used to practice python, since this whole project is written using the language Python (version 3.7.6). Youtube is required to actually learn the language and the hyperlink on the word \"Youtube\" earlier links to a channel called Corey Schafer, from which all the learning for python, and its various packages were done.\n",
    "\n",
    "\n",
    "3. Speaking of packages, the there are only 3 packages required for this project which are Keras, Sklearn and finally tensorflow. All of these can be installed by opening up Visual Studio Code, opening a new terminal by clicking on terminal on the top taskbar, and typing in \"pip install keras\", wait for it to install, \"pip install sklearn\", waiting for Sklearn to install, and finally \"pip install tensorflow\", and allow tensorflow(make sure version 2.1.0 is installing) to finish installing. Note that the full extent of some packages are not used, rather a parts of it or \"Modules\" are used.\n",
    "\n",
    "\n",
    "4. A lot of time, around 100 to 120 hours of work are required to finish the project. 60 hours are required to learn python, 20 to learn about machine learning and another 20 hours to actually code. This may take longer or shorter depending on the amount of coding/python known. \n",
    "\n",
    "\n",
    "5. A website known as [Markdown Tables gererator](https://www.tablesgenerator.com/markdown_tables) which allows for the data table of this project to be created and embedded into the markdown cells(text cells instead of code cells) with ease.\n",
    "\n",
    "\n",
    "6. Also, this project has a link further on to the mnist database of handwritten numbers, but that is just for ease of access, as keras has a module through which mnist can be imported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safety precautions or Collection Concerns: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the final iteration of the project is collected using an algorithm in the algorithm. Akin to a data collection journal, the program has an initialized dictionary, or a set of values that are updated for each data set(For example 1000 images, or 2000 images  for training). Each data set is like a different entry into the dictionary, with its own results. The algorithm/formula uses a for loop to test each data set and at the end, the results are appended into the dictionary. This ensures that no data is lost, and everything is collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!: The procedure details the actual coding part of the project, assuming that the reader already knows python and has installed all of the packages necessary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: import all the necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem like a lot, but it's actually not. Using just 2 packages, keras(Tensorflow is used by keras, and so it is neccessary to install tensorflow) and sklearn, all the modules and everything needed for this project is imported. The main things to take not of from keras are mnist, and conv2d. [Mnist](http://yann.lecun.com/exdb/mnist/) is the database from which the labeled numerical digits are imported. Conv2d is just a module which helps to build a convolutional neural network(Refer to the image below). From sklearn, the main module to be noted is train_test_split, which allows us to vary the amount of training data.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image of a convolutional neural network:\n",
    "\n",
    "![Image of a convolutional neural network](https://cdn-images-1.medium.com/fit/t/1600/480/1*vkQ0hXDaQv57sALXAJquxA.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Write a function to load the MNIST database into training and testing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(test_size_per):\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    print(x_train.shape, y_train.shape)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=test_size_per)\n",
    "    print(x_train.shape)\n",
    "    return x_train, y_train, x_test, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get into the actual coding bit of the project. This is one of 3 functions in this project. The name of it being \"load_minst_data\". This does exactly what the name suggests and loads the variables with training and test data. The variables being x_train, y_train, x_test, and y_test. x and y are not coordinates, but rather x is the input and y is the output. The training variables, x_train, and  y_train are where all the training images that the computer uses to learn are kept. While x_test, and y_test are where the testing images are kept. These images are what the computer tests itself on to refine the algorithm. There are 60,000 images in the mnist database and by default, 50,000 are kept for training and the remaining 10,000 are used as testing images. on the 4th and 5th lines of the cell, the function train_test_split() is used to split the data into training and testing images by taking a percentage value which is then applied to the database and made into the test set. For example, if the percentage is given as 0.5 or 50%, 30,000 images would be used as testing and 30,000 for training. This is not a set value however, there is a parameter known as test_size_per which allows the percentage to be changed every time the function is called upon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image shows a sample image from the mnist database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Handwritten 8 in the MNIST database](https://miro.medium.com/max/490/1*nlfLUgHUEj5vW7WVJpxY-g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the image is graphed and has a size of 28  x 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Write a function to reshape, and prepare all the images uniformly for input into the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(x_train, y_train, x_test, y_test):\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the most important parts of the whole algorithm, second only to the actual machine learning part itself. All the images are now reshaped into 28 x 28, just in case some of them were not that size. Furthermore, this uniformity allows the computer to look at all of the images consistently the same. Furthermore, all the images are shuffled, so that certain patterns and exclusions of digits do not occur, therefore removing the chance that the computer's \"learning\" is skewed. In summation, this function allows for the uniformity of the images so that the computer sees every image equally and is not skewed by unnatural patterns such as the abscence of a certain digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Writing a function to setup the model, train the model, and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(x_train, y_train, x_test, y_test ):\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 10\n",
    "\n",
    "    input_shape = (28, 28, 1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "    hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "    print(\"The model has successfully trained\")\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "\n",
    "    model.save('mnist.h5')\n",
    "    print(\"Saving the model as mnist.h5\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is what sets up a model(convolutional neural network), and trains it with the training set. This is still a function, and is not executing anything, so no output is given. The way a machine learning model learns/trains itself is that it uses differential calculus. Bascially, an inverse parabola is graphed internally, called the gradient descent that allows the computer to see where it is. The x axis is the answer that it is guessing. For example, an eight is given as an input, and the computer guesses that it's a 5. Now, that is the wrong answer, but atleast the computer now knows that the eight is not a 5. The y axis is the cost. Basically the higher the cost, the farther the model is from the answer. Graphing this would show an inverse parabola, where the answer(the number eight in the example) on the x axis, and the lowest value on the y axis(the cost) are located. The end goal of the model is to reach that low point. once it does, and it gets a problem correct, it moves on and uses the same formula that it used for the previous one. Basically, the computer at first uses random values, and then narrows it down to the correct value, and uses the formula that got it the correct values. This is all calculated in a matter of mere seconds though. This is why a larger training set, like common sense would tell us, makes the computer more accurate in its learning and testing. Below is an image of the gradient descent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Gradient Descent](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Executing the functions in a for loop, so that each iteration, a bigger training set is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_values = {}\n",
    "\n",
    "#Takes increasingly more images to increase the accuracy\n",
    "training_sets = [100, 200, 500, 750, 1500, 2000, 5000, 6000, 10000, 20000, 40000, 50000]\n",
    "\n",
    "for test_per in training_sets:\n",
    "    training_per = 1- (test_per/60000) #calculation is giving the test percentage\n",
    "    print(training_per)\n",
    "    x_train, y_train, x_test, y_test = load_mnist_data(training_per)\n",
    "    print('Testing with train set size of: ', x_train.shape)\n",
    "    x_train, y_train, x_test, y_test = prepare_input(x_train, y_train, x_test, y_test)\n",
    "    score = setup_model(x_train, y_train, x_test, y_test)\n",
    "    summary_values[x_train.shape] = {test_per/100, score[0], score[1]}\n",
    "\n",
    "print(summary_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final step for this project and does not involve much. The three main things that are part of this step are the variables summary_values, training_sets and the for loop. The variable summary_values is a dictionary variable that allows for the ending data for each training size to be collected and stored safely. This variable is printed at the end to allow for easy data collection. The variable training_sets is used in conjunction with the for loop to iterate through each amount of training images. The variable test_per is being iterated with each value in the array training_sets and is converted into a percentage to be put into the function load_mnist_data and specify what percent of the images are training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link for the same project but in Visual studio code for ease of copying and pasting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Harshith0307/Machine_Learning/blob/master/minst_handwriting.py\n",
    "\n",
    "You can copy and paste this into Visual Studio Code, and if all the packages are installed, it will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bibliography for all of the information used in this project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical analysis. (2020). In Encyclopædia Britannica. Retrieved from https://school.eb.com/levels/high/article/numerical-analysis/108506#\n",
    "\n",
    "Published in Encyclopedia Britannica, this article discusses numerical analysis and all its applications. The main focus of this article is numerical analysis’ use in computer science and data science applications. This details numerical regressions and algorithms that are regularly used to find correlations within data sets and serve as a basis for almost all machine learning algorithms.\n",
    "\n",
    "Encyclopedia Britannica, the publisher of the article, is a British encyclopedia publisher that has long been renowned for having extremely neutral and unbiased content. Britannica has been publishing since 1768 and is a reliable source of information for research purposes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Understanding How Python is Used in Data Science. (n.d.). Retrieved January 25, 2020, from https://www.datasciencegraduateprograms.com/python/ \n",
    "\n",
    "Published on Data Science Graduate Programs, this article discusses the uses of Python within the realm of data science. Python is an object-oriented programming language that is used in data science for its versatility, and ease of operating with additional libraries for an overall very simple approach to data science and machine learning. This article outlines the uses of Python in Data Science and how python efficiently and effectively fulfills that goal.\n",
    "\n",
    "Data Science Graduate Programs is a California based website staffed by professors in California. It serves as a website to get high school graduates into college for data science and outlines the positives of the data science career. It is a reliable and unbiased source and has been publishing since 2011.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Brownlee, Jason. (2019, August 9). Introduction to Matrices and Matrix Arithmetic for Machine Learning. Retrieved February 2, 2020, from https://machinelearningmastery.com/introduction-matrices-machine-learning/\n",
    "\n",
    "Matrices are a fundamental element in linear algebra. They are used widely in the realm of machine learning especially in the input data variable(x) to train the algorithm. A matrix is at its lowest complexity, an array within an array with columns and rows. Matrices can be used in arithmetic operations as well and have been made greatly easier by python libraries such as pandas, and NumPy.\n",
    "\n",
    "Jason Brownlee Ph.D. is a professional python developer and machine learning practitioner. He started writing a series of articles about machine learning with python because he wants to get new developers started in machine learning and get them good fast. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "General Python FAQ¶. (n.d.). Retrieved January 25, 2020, from https://docs.python.org/2/faq/general.html#what-is-python \n",
    "\n",
    "Python is an object-oriented language. It is a high-level programming language that incorporates a large number of modules, libraries, classes and has a lot of the features that make other programming languages like C, C#, and Java popular. Python is also a portable programming language like Java and can be used on almost all kinds of software.\n",
    "\n",
    "Python.org is a nonprofit website created to house the python documentation, its source code, and other frequently asked questions about python. It also has sections written by and sections with interviews with the original creator of python, Guido Van Rossum.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dataman. (2019, November 20). What Is Image Recognition? Retrieved February 2, 2020, from https://towardsdatascience.com/module-6-image-recognition-for-insurance-claim-handling-part-i-a338d16c9de0\n",
    "\n",
    "Image recognition is exactly what it sounds like. It is the recognition of images. The human brain makes this really easy, but computers, on the other hand, don’t have the intuition that humans have to recognize and evaluate images. There are 4 steps that are required to teach computers how to recognize images. First, all images are made up of pixels and you need to extract them from the image. Secondly, classify those pixels into labeled data sets. Thirdly, the hardest step, train the machine to be able to recognize images. lastly, Predict a new image that classifies under one of the categories. \n",
    "\n",
    "Towards Data Science us an online journal about machine learning, and artificial intelligence written by a variety of authors who are experts in the topic. They strive to provide well written and informative articles that their audience wants to read. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "About pandas. (n.d.). Retrieved February 2, 2020, from https://pandas.pydata.org/about/index.html\n",
    "\n",
    "Pandas is a language library written for the Python programming language. It is mainly a data science library with many applications for machine learning and artificial intelligence. Pandas mainly deals with matrices and large data sets. Pandas is also open source so any developer can suit it to his or her needs.\n",
    "\n",
    "Pandas aims to be the fundamental high-level building block for doing practical data analysis in Python. Additionally, it has the broader goal of becoming a powerful and flexible open-source data analysis/manipulation tool available in any language.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Saha, S. (2018, December 17). A Comprehensive Guide to Convolutional Neural Networks - the ELI5 way. Retrieved March 17, 2020, from https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n",
    "\n",
    "The image of the convolutional neural network at the top of the article is used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Yal, O. G. (2020, March 4). Image Classification in 10 Minutes with MNIST Dataset. Retrieved March 17, 2020, from https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\n",
    "\n",
    "An image of the mnist database from the article is used to illustrate how the database's images look\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Bhattarai, S. (2018, September 4). What is Gradient Descent in machine learning? Retrieved March 17, 2020, from https://saugatbhattarai.com.np/what-is-gradient-descent-in-machine-learning/\n",
    "\n",
    "An image of gradiel descent is used from the article."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
